---
title: "Modeling binary choice data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Modeling binary choice data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(tempodisco)
```

## Classic methods

For binary choice data not explicitly designed to titrate out indifference points (as in an adjusting amount procedure), there are a few analysis options. A common one is the scoring method designed for the Monetary Choice Questionnaire [(Kirby, 1999)](https://doi.org/10.1037//0096-3445.128.1.78):

```{r}
data("td_bc_single_ptpt")
mod <- kirby_score(td_bc_single_ptpt)
print(mod)
```

Although this method computes $k$ values according to the hyperbolic discount function, in principle it's possible to use the exponential discount function:

```{r}
mod <- kirby_score(td_bc_single_ptpt, discount_function = 'exponential')
print(mod)
```

Another option is to use the logistic regression method of [Wileyto et al. (2004)](https://doi.org/10.3758/BF03195548), where we can solve for the $k$ value of the hyperbolic discount function in terms of the regression coefficients:

```{r}
mod <- wileyto_score(td_bc_single_ptpt)
print(mod)
```

## Newer methods

The [Wileyto et al. (2004)](https://doi.org/10.3758/BF03195548) approach turns out to be possible for other discount functions as well [(Kinley et al., 2024)](https://doi.org/10.31234/osf.io/y2fdh). A full list is below:

| Name | Discount function | Linear predictor | Parameters |
|--|--|--|--|
| `hyperbolic.1` | Hyperbolic ([Mazur, 1987](https://doi.org/10.4324/9781315825502)):<br><br>$\frac{1}{1 + kt}$ | $\beta_1 \left(1 - \frac{v_D}{v_I} \right) + \beta_2 t$ | $k = \frac{\beta_2}{\beta_1}$ | 
| `hyperbolic.2` | ([Mazur, 1987](https://doi.org/10.4324/9781315825502)):<br><br>$\frac{1}{1 + kt}$ | $\beta_1\left( \sigma^{-1}\left[\frac{v_\mathcal{I}}{v_\mathcal{D}}\right] + \log t \right) + \beta_2$ | $k = e^\frac{\beta_2}{\beta_1}$ |
| `exponential.1` | Exponential ([Samuelson, 1937](https://doi.org/10.2307/2967612)):<br><br>$e^{-kt}$ | $\beta_1 \log \frac{v_I}{v_D} + \beta_2 t$ | $k = \frac{\beta_2}{\beta_1}$ |
| `exponential.2` | Exponential ([Samuelson, 1937](https://doi.org/10.2307/2967612)):<br><br>$e^{-kt}$ | $\beta_1\left( G^{-1}\left[\frac{v_\mathcal{I}}{v_\mathcal{D}}\right] + \log t \right) + \beta_2$ | $k = e^\frac{\beta_2}{\beta_1}$ |
| `scaled-exponential` | Scaled exponential (beta-delta; [Laibson, 1997](https://doi.org/10.1162/003355397555253)):<br><br>$w e^{-kt}$ | $\beta_1\log\frac{v_{I}}{v_{D}} + \beta_2 t + \beta_3$ | $k = \frac{\beta_2}{\beta_1}$, $w = e^{-\frac{\beta_3}{\beta_1}}$ |
| `nonlinear-time-hyperbolic` | Nonlinear-time hyperbolic ([Rachlin, 2006](https://doi.org/10.1901/jeab.2006.85-05)):<br><br>$\frac{1}{1 + k t^s}$ | $\beta_1 \sigma^{-1}\left[\frac{v_{I}}{v_{D}}\right] + \beta_2\log t + \beta_3$ | $k = e^\frac{\beta_3}{\beta_1}$, $s = \frac{\beta_2}{\beta_1}$ |
| `nonlinear-time-exponential` | Nonlinear-time exponential ([Ebert & Prelec, 2007](https://doi.org/10.1287/mnsc.1060.0671)):<br><br>$e^{-kt^s}$ | $\beta_1 G^{-1}\left[\frac{v_\mathcal{I}}{v_\mathcal{D}}\right] + \beta_2\log t + \beta_3$ | $k = e^\frac{\beta_3}{\beta_1}$, $s = \frac{\beta_2}{\beta_1}$ |

We can test all of these and select the best according to the Bayesian Information Criterion as follows:

```{r}
mod <- td_bclm(td_bc_single_ptpt, model = 'all')
print(mod)
```

To explore a wider range of discount functions, we can fit a nonlinear model by calling `td_bcnm`. The full list is as follows:

| Name | Functional form |
|------|-----------------|
| Exponential ([Samuelson, 1937](https://doi.org/10.2307/2967612)) |	$f(t; k) = e^{-k t}$ |
| Scaled exponential (beta-delta; [Laibson, 1997](https://doi.org/10.1162/003355397555253)) | $f(t; k, w) = w e^{-k t}$ |
| Nonlinear-time exponential ([Ebert & Prelec, 2007](https://doi.org/10.1287/mnsc.1060.0671)) | $f(t; k, s) = e^{-k t^s}$ |
| Dual-systems exponential ([Ven den Bos & McClure, 2013](https://doi.org/10.1002/jeab.6)) | $f(t; k_1, k_2, w) = w e^{-k_1 t} + (1 - w) e^{-k_2 t}$ |
| Inverse q-exponential ([Green & Myerson, 2004](https://doi.org/10.1037/0033-2909.130.5.769)) | $f(t; k, s) = \frac{1}{(1 + k t)^s}$ |
| Hyperbolic ([Mazur, 1987](https://doi.org/10.4324/9781315825502)) | $f(t; k) = \frac{1}{1 + kt}$ |
| Nonlinear-time hyperbolic ([Rachlin, 2006](https://doi.org/10.1901/jeab.2006.85-05)) | $f(t; k, s) = \frac{1}{1 + k t^s}$ |

```{r}
mod <- td_bcnm(td_bc_single_ptpt, discount_function = 'all')
print(mod)
```

Several additional arguments can be used to customize the model. For example, we can use different choice rules---the "logistic" choice rule is the default, but the "probit" and "power" choice rules are also available (see [Wulff and Van den Bos, 2018](https://doi.org/10.1177/0956797616664342), for explanations of these):

```{r}
# Probit choice rule:
mod <- td_bcnm(td_bc_single_ptpt, discount_function = 'exponential', choice_rule = 'probit')
# Power choice rule:
mod <- td_bcnm(td_bc_single_ptpt, discount_function = 'exponential', choice_rule = 'power')
```

It is also possible to fit an error rate $\epsilon$ that describes the probability of the participant making a response error (see [Vincent, 2015](https://doi.org/10.3758/s13428-015-0672-2)). I.e.:
$$P(\text{imm}) = \epsilon + (1 - 2\epsilon) g^{-1}[\eta]$$
where $P(\text{imm})$ is the probability of choosing the immediate reward, $g$ is the link function, and $\eta$ is the linear predictor.

```{r}
data("td_bc_study")
# Select the second participant
second_ptpt <- unique(td_bc_study$id)[2]
df <- subset(td_bc_study, id == second_ptpt)
mod <- td_bcnm(df, discount_function = 'exponential', fit_err_rate = T)
plot(mod, type = 'endpoints', verbose = F)
lines(c(0, 1), c(0, 0), lty = 2)
lines(c(0, 1), c(1, 1), lty = 2)
```

We can see that the probability of choosing the immediate reward doesn't approach 0 or 1.

Alternatively, we might expect that participants should never choose an immediate reward worth 0 and should never choose a delayed reward worth the same face amount as an immediate reward [(Kinley et al., 2024)](https://doi.org/10.31234/osf.io/y2fdh). We can control this by setting `fixed_ends = T`, which "fixes" the endpoints of the psychometric curve, where `val_imm = 0` and `val_imm = val_del`, at 0 and 1, respectively:

```{r}
mod <- td_bcnm(df, discount_function = 'exponential', fixed_ends = T)
plot(mod, type = 'endpoints', verbose = F)
```
